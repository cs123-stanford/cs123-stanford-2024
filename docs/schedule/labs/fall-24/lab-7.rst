Lab 6: Do What I Say (LLMs and Voice Control)
=============================================

*Goal: For this lab, you will explore with we can use LLMs and speech recognition to control Pupper to do a variety of tasks! Next you will benchmark this method against using a pre-trained CNN or Resnet architecture for speech recognition.*

Step 1. Clone the starter code into the Pupper
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

   .. code-block:: bash

      cd ~/
      git clone https://github.com/cs123-stanford/pupper_llm_student.git pupper_llm

Step 2. Use the Karel Pupper API
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

For much of this lab, we will be using the Karel Pupper API. Much like the 

Step 3. Create a Simple Chat with GPT Throught the Command Line
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

**DELIVERABLE:** Experiment with different prompts. Engineer a prompt that you can use to control Pupper at a high level.
